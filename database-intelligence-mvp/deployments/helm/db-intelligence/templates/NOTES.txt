1. Get the application status by running these commands:
{{- if .Values.ingress.enabled }}
{{- range $host := .Values.ingress.hosts }}
  {{- range .paths }}
  http{{ if $.Values.ingress.tls }}s{{ end }}://{{ $host.host }}{{ .path }}
  {{- end }}
{{- end }}
{{- else if contains "NodePort" .Values.service.type }}
  export NODE_PORT=$(kubectl get --namespace {{ .Release.Namespace }} -o jsonpath="{.spec.ports[0].nodePort}" services {{ include "database-intelligence.fullname" . }})
  export NODE_IP=$(kubectl get nodes --namespace {{ .Release.Namespace }} -o jsonpath="{.items[0].status.addresses[0].address}")
  echo http://$NODE_IP:$NODE_PORT
{{- else if contains "LoadBalancer" .Values.service.type }}
     NOTE: It may take a few minutes for the LoadBalancer IP to be available.
           You can watch the status of by running 'kubectl get --namespace {{ .Release.Namespace }} svc -w {{ include "database-intelligence.fullname" . }}'
  export SERVICE_IP=$(kubectl get svc --namespace {{ .Release.Namespace }} {{ include "database-intelligence.fullname" . }} --template "{{"{{ range (index .status.loadBalancer.ingress 0) }}{{.}}{{ end }}"}}")
  echo http://$SERVICE_IP:{{ .Values.service.port }}
{{- else if contains "ClusterIP" .Values.service.type }}
  export POD_NAME=$(kubectl get pods --namespace {{ .Release.Namespace }} -l "app.kubernetes.io/name={{ include "database-intelligence.name" . }},app.kubernetes.io/instance={{ .Release.Name }}" -o jsonpath="{.items[0].metadata.name}")
  export CONTAINER_PORT=$(kubectl get pod --namespace {{ .Release.Namespace }} $POD_NAME -o jsonpath="{.spec.containers[0].ports[0].containerPort}")
  echo "Visit http://127.0.0.1:8080 to use your application"
  kubectl --namespace {{ .Release.Namespace }} port-forward $POD_NAME 8080:$CONTAINER_PORT
{{- end }}

2. Check the collector health:
  kubectl --namespace {{ .Release.Namespace }} get pods -l "app.kubernetes.io/name={{ include "database-intelligence.name" . }},app.kubernetes.io/instance={{ .Release.Name }}"
  
  # View logs
  kubectl --namespace {{ .Release.Namespace }} logs -l "app.kubernetes.io/name={{ include "database-intelligence.name" . }},app.kubernetes.io/instance={{ .Release.Name }}" -f

3. Access collector endpoints:
  # Health check
  curl http://localhost:13133/ 
  
  # Metrics endpoint
  curl http://localhost:8888/metrics
  
  # Debug endpoints (if enabled)
  curl http://localhost:55680/debug/tracez
  curl http://localhost:6061/debug/pprof/

4. Verify data collection:
{{- if .Values.config.mode }}
  Mode: {{ .Values.config.mode }}
{{- end }}
  
  Check that metrics are being collected from your databases:
  - PostgreSQL: {{ .Values.config.receivers.postgresql.endpoint | default "localhost:5432" }}
  - MySQL: {{ .Values.config.receivers.mysql.endpoint | default "localhost:3306" }}

5. Monitor in New Relic:
  Log into your New Relic account and navigate to:
  - Infrastructure > Third-party services > OpenTelemetry
  - Query Builder: FROM Metric SELECT * WHERE otel.library.name LIKE 'otelcol%'

{{- if .Values.config.mode | eq "experimental" }}

‚ö†Ô∏è  EXPERIMENTAL MODE ENABLED ‚ö†Ô∏è
You are running with experimental features that include:
- Adaptive Sampling
- Circuit Breaker Protection
- Plan Attribute Extraction
- Verification Processor

Monitor resource usage closely and ensure single-instance deployment.
{{- end }}

{{- if .Values.persistence.enabled }}

üìÅ Persistent storage is enabled. Data will be stored in:
  {{ .Values.persistence.size }} volume at /var/lib/otel/
{{- end }}

{{- if .Values.autoscaling.enabled }}

üöÄ Autoscaling is enabled:
  Min replicas: {{ .Values.autoscaling.minReplicas }}
  Max replicas: {{ .Values.autoscaling.maxReplicas }}
  Target CPU: {{ .Values.autoscaling.targetCPUUtilizationPercentage }}%
{{- end }}

For more information, visit:
https://github.com/database-intelligence-mvp/database-intelligence-mvp