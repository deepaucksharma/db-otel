# Database Intelligence MVP - Docker Deployment Configuration
# Optimized for Docker container environment

extensions:
  health_check:
    endpoint: 0.0.0.0:13133
  
  file_storage:
    directory: /var/lib/otel/storage
    timeout: 10s
    compaction:
      directory: /var/lib/otel/storage/compaction
      on_start: true
      on_rebound: true
      rebound_needed_threshold_mib: 100
      rebound_trigger_threshold_mib: 10
  
  zpages:
    endpoint: 0.0.0.0:55679

receivers:
  # PostgreSQL Query Plan Receiver
  sqlquery/postgresql_plans_safe:
    driver: postgres
    dsn: "${env:PG_REPLICA_DSN}"
    
    # Docker-optimized settings
    collection_interval: 60s
    timeout: 5s
    max_idle_time: 60s
    max_lifetime: 300s
    max_open_connections: 2
    max_idle_connections: 1
    
    queries:
    - sql: |
        -- MANDATORY SAFETY TIMEOUTS
        SET LOCAL statement_timeout = '2000';
        SET LOCAL lock_timeout = '100';
        
        -- Production Query: Single worst performer
        WITH worst_query AS (
          SELECT 
            queryid,
            query,
            mean_exec_time,
            calls,
            total_exec_time,
            (mean_exec_time * calls) as impact_score
          FROM pg_stat_statements
          WHERE 
            mean_exec_time > 100
            AND calls > 10
            AND query NOT LIKE '%pg_%'
            AND query NOT LIKE '%EXPLAIN%'
            AND query NOT LIKE '%information_schema%'
            AND length(query) < 4000
          ORDER BY impact_score DESC
          LIMIT 1
        )
        SELECT
          w.queryid::text as query_id,
          w.query as query_text,
          w.mean_exec_time as avg_duration_ms,
          w.calls as execution_count,
          w.total_exec_time as total_duration_ms,
          w.impact_score::bigint as impact_score,
          now() as collection_timestamp,
          current_database() as database_name,
          version() as pg_version,
          '{}' as plan_json
        FROM worst_query w;

  # Zero-Impact File Log Collection
  filelog/pg_auto_explain:
    include: 
    - /var/log/postgresql/postgresql-*.log
    - /var/log/postgresql/*.log
    exclude:
    - /var/log/postgresql/*.gz
    - /var/log/postgresql/*.bz2
    
    start_at: end
    max_log_size: 10MiB
    max_concurrent_files: 10
    
    multiline:
      line_start_pattern: '^\d{4}-\d{2}-\d{2}\s+\d{2}:\d{2}:\d{2}'
      max_log_size: 1MiB
      timeout: 5s
    
    operators:
    - type: regex_parser
      id: extract_plan
      regex: '^(?P<timestamp>\d{4}-\d{2}-\d{2}\s+\d{2}:\d{2}:\d{2}.\d+\s+\w+).*duration:\s+(?P<duration>\d+\.\d+)\s+ms.*plan:\s*(?P<plan>\{.*\}).*$'
      on_error: send
      
    - type: json_parser
      id: parse_plan
      parse_from: attributes.plan
      parse_to: body.plan
      on_error: send_quiet
      
    - type: add
      id: add_metadata
      fields:
        attributes.db.system: postgresql
        attributes.db.source: auto_explain
        attributes.collection.method: zero_impact

processors:
  # Memory Protection - ALWAYS FIRST
  memory_limiter:
    check_interval: 1s
    limit_mib: 512
    spike_limit_mib: 128
    ballast_size_mib: 64

  # PII Sanitization - ALWAYS SECOND
  transform/sanitize_pii:
    error_mode: ignore
    log_statements:
    - context: log
      statements:
      # Email addresses
      - replace_all_patterns(
          attributes,
          "value",
          "\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b",
          "[EMAIL]"
        )
      
      # Social Security Numbers
      - replace_pattern(body, "\\b\\d{3}-\\d{2}-\\d{4}\\b", "[SSN]")
      - replace_pattern(body, "\\b\\d{9}\\b", "[SSN]")
      
      # Credit Card Numbers
      - replace_pattern(
          body,
          "\\b\\d{4}[\\s-]?\\d{4}[\\s-]?\\d{4}[\\s-]?\\d{4}\\b",
          "[CARD]"
        )
      
      # Phone Numbers
      - replace_pattern(
          body,
          "\\b(?:\\+1[\\s-]?)?\\(?\\d{3}\\)?[\\s-]?\\d{3}[\\s-]?\\d{4}\\b",
          "[PHONE]"
        )
      
      # SQL Literals
      - replace_pattern(
          attributes["query_text"],
          "'[^']*'",
          "'[LITERAL]'"
        )

  # Metadata Enrichment
  transform/enrich_metadata:
    error_mode: ignore
    log_statements:
    - context: log
      statements:
      - set(attributes["db.intelligence.version"], "mvp-1.0")
      - set(attributes["db.intelligence.collector"], "docker")
      - set(attributes["collection.timestamp"], Now())
      - set(attributes["container.name"], "nr-db-intelligence-collector")

  # Temporary: Use probabilistic sampler until custom processors are built
  probabilistic_sampler:
    sampling_percentage: 10.0
    hash_seed: 22

  # Batching for efficiency
  batch:
    timeout: 10s
    send_batch_size: 100
    send_batch_max_size: 500

exporters:
  # New Relic OTLP Export
  otlp:
    endpoint: "${env:OTLP_ENDPOINT}"
    
    headers:
      api-key: "${env:NEW_RELIC_LICENSE_KEY}"
    
    compression: gzip
    
    retry_on_failure:
      enabled: true
      initial_interval: 5s
      max_interval: 30s
      max_elapsed_time: 300s
      randomization_factor: 0.5
      multiplier: 1.5
    
    sending_queue:
      enabled: true
      num_consumers: 4
      queue_size: 100
    
    timeout: 30s
    
    tls:
      insecure: false

  # Debug exporter for troubleshooting
  debug:
    verbosity: basic
    sampling_initial: 1
    sampling_thereafter: 100

service:
  extensions:
  - health_check
  - file_storage
  - zpages
  
  pipelines:
    logs/database_plans:
      receivers:
      - sqlquery/postgresql_plans_safe
      - filelog/pg_auto_explain
      processors:
      - memory_limiter           # Safety first
      - transform/sanitize_pii   # Security second
      - transform/enrich_metadata # Add context
      - probabilistic_sampler    # Temporary sampling
      - batch                    # Efficiency last
      exporters:
      - otlp
      # - debug  # Enable for troubleshooting
  
  # Self-monitoring
  telemetry:
    logs:
      level: "${env:OTEL_LOG_LEVEL}"
      development: false
      encoding: json
      output_paths: ["/var/log/otel/collector.log"]
      error_output_paths: ["stderr"]
      initial_fields:
        service: database-intelligence-collector
        version: mvp-1.0
        deployment: docker
        environment: "${env:DEPLOYMENT_ENV}"
    
    metrics:
      level: detailed
      address: 0.0.0.0:8888
    
    resource:
      service.name: database-intelligence-collector
      service.version: mvp-1.0
      deployment.environment: "${env:DEPLOYMENT_ENV}"
      container.name: nr-db-intelligence-collector